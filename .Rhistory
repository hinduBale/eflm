y = sum(trade),
log_y = log(y)
) %>%
# Create Eit
group_by(importer, year) %>%
mutate(
e = sum(trade),
log_e = log(e)
)
ch1_application1_2 <- ch1_application1_2 %>%
# Replicate total_e
group_by(exporter, year) %>%
mutate(total_e = sum(e)) %>%
group_by(year) %>%
mutate(total_e = max(total_e)) %>%
# Replicate rem_exp
group_by(exporter, year) %>%
mutate(
remoteness_exp = sum(dist *  total_e / e),
log_remoteness_exp = log(remoteness_exp)
) %>%
# Replicate total_y
group_by(importer, year) %>%
mutate(total_y = sum(y)) %>%
group_by(year) %>%
mutate(total_y = max(total_y)) %>%
# Replicate rem_imp
group_by(importer, year) %>%
mutate(
remoteness_imp = sum(dist / (y / total_y)),
log_remoteness_imp = log(remoteness_imp)
)
ch1_application1_2 <- ch1_application1_2 %>%
# This merges the columns exporter/importer with year
mutate(
exp_year = paste0(exporter, year),
imp_year = paste0(importer, year)
)
ch1_application1_2 <- ch1_application1_2 %>%
filter(exporter != importer)
saveRDS(ch1_application1_2, fout, compress = "xz")
} else {
ch1_application1_2 <- readRDS("ch1_application1_2.rds")
}
# NEVER PUT THIS ON TESTS/ FOLDER
# THE DATA IS TOO LARGE AND TAKES +5 MINUTES TO FIT THE MODEL
if (!require(dplyr)) install.packages("dplyr")
if (!require(eflm)) install.packages("eflm")
if (!require(microbenchmark)) install.packages("microbenchmark")
library(dplyr)
library(eflm)
library(microbenchmark)
fout <- "ch1_application1_2.rds"
if (!file.exists(fout)) {
if (!require(yotover)) install.packages("yotover")
library(yotover)
ch1_application1_2 <-  yotov_data("ch1_application1") %>%
filter(year %in% seq(1986, 2006, 4))
ch1_application1_2 <- ch1_application1_2 %>%
mutate(
log_trade = log(trade),
log_dist = log(dist)
)
ch1_application1_2 <- ch1_application1_2 %>%
# Create Yit
group_by(exporter, year) %>%
mutate(
y = sum(trade),
log_y = log(y)
) %>%
# Create Eit
group_by(importer, year) %>%
mutate(
e = sum(trade),
log_e = log(e)
)
ch1_application1_2 <- ch1_application1_2 %>%
# Replicate total_e
group_by(exporter, year) %>%
mutate(total_e = sum(e)) %>%
group_by(year) %>%
mutate(total_e = max(total_e)) %>%
# Replicate rem_exp
group_by(exporter, year) %>%
mutate(
remoteness_exp = sum(dist *  total_e / e),
log_remoteness_exp = log(remoteness_exp)
) %>%
# Replicate total_y
group_by(importer, year) %>%
mutate(total_y = sum(y)) %>%
group_by(year) %>%
mutate(total_y = max(total_y)) %>%
# Replicate rem_imp
group_by(importer, year) %>%
mutate(
remoteness_imp = sum(dist / (y / total_y)),
log_remoteness_imp = log(remoteness_imp)
)
ch1_application1_2 <- ch1_application1_2 %>%
# This merges the columns exporter/importer with year
mutate(
exp_year = paste0(exporter, year),
imp_year = paste0(importer, year)
)
ch1_application1_2 <- ch1_application1_2 %>%
filter(exporter != importer)
saveRDS(ch1_application1_2, fout, compress = "xz")
} else {
ch1_application1_2 <- readRDS("ch1_application1_2.rds")
}
benchmark_times <- microbenchmark(
glm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,
family = quasipoisson(link = "log"),
data = ch1_application1_2,
y = FALSE,
model = FALSE
),
eglm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,
family = quasipoisson(link = "log"),
data = ch1_application1_2,
y = FALSE,
model = FALSE
),
times = 1L
)
benchmark_times
library(digitalocean)
r <- regions()
r <- regions()
r <- regions()
library(digitalocean)
r <- regions()
r <- regions()
library(analogsea)
install.packages("analogsea")
analogsea::regions()
library(digitalocean)
r <- regions()
library(digitalocean)
r <- regions()
s <- sizes()
r
View(r)
View(s)
library(dplyr)
s <- s %>% filter(grepl("tor", region))
s <- s %>%
filter(
grepl("tor", region),
grepl("vcpu", slug)
)
s <- s %>%
filter(
grepl("tor", region),
grepl("vcpu", slug),
memory >= 4096
)
s <- s %>%
filter(
grepl("tor", region),
grepl("vcpu", slug),
memory >= 4096
) %>%
arrange(slug)
library(purrr)
library(digitalocean)
library(digitalocean)
library(dplyr)
library(purrr)
library(digitalocean)
library(dplyr)
library(purrr)
# oauth needed for r,s!
r <- regions()
s <- sizes()
s <- s %>%
filter(
grepl("tor", region),
grepl("vcpu", slug),
memory >= 4096
) %>%
arrange(slug)
# create the 9 droplets (R + RStudio included)
map(
s$slug,
function(x) {
droplet_create(name = x, size = x)
}
)
droplets <- list()
seq_along(s$slug)
droplets[[1]] <- 1111
droplets
names(droplets[[1]]) = " aaaa"
droplets
droplets <- list()
droplets[[1]] <- 1111
names(droplets[[1]]) = " aaaa"
droplets
droplets <- c()
droplets <- list()
droplets[1] <- 1111
names(droplets[1]) = " aaaa"
droplets
droplets <- c()
droplets[1] <- 1111
names(droplets[1]) = " aaaa"
droplets
droplets[2] <- 2222
names(droplets[2]) = "bbb"
droplets
droplets <- s$slug
droplets <- s$slug
names(droplets) <- s$slug
droplets
droplets[1] <- 1111
droplets
droplets <- s$slug
names(droplets) <- s$slug
droplets
writeLines(benchmark_times, "dev/benchmarktimes.txt")
# create the 9 droplets (R + RStudio included)
map(
seq_along(s$slug),
function(x) {
droplets[x] <- droplet_create(name = s$slug[x], size = s$slug[x], wait = F)
}
)
droplets
droplets
droplets
# create the 9 droplets (R + RStudio included)
map(
seq_along(s$slug),
function(x) {
droplets[[x]] <- droplet_create(name = s$slug[x], size = s$slug[x], wait = F)
}
)
droplets
droplets <- s$slug
names(droplets) <- s$slug
x = 1
droplets[x]
s$slug[x]
s$slug[x]
droplets <- list(s$slug)
names(droplets) <- s$slug
droplets
droplets <- as.list(s$slug)
names(droplets) <- s$slug
droplets
droplets <- as.list(s$slug)
names(droplets) <- janitor::make_clean_names(s$slug)
install.packages("janitor")
droplets
droplets <- as.list(s$slug)
names(droplets) <- janitor::make_clean_names(s$slug)
droplets
x
droplets[[x]] <- droplet_create(name = s$slug[x], size = s$slug[x], wait = F)
droplets
droplets
droplet_delete(droplets[[x]])
droplets <- as.list(s$slug)
names(droplets) <- janitor::make_clean_names(s$slug)
# create the 9 droplets (R + RStudio included)
map(
seq_along(s$slug),
function(x) {
droplets[[x]] <- droplet_create(name = s$slug[x], size = s$slug[x], wait = F)
}
)
# NEVER PUT THIS ON TESTS/ FOLDER
# THE DATA IS TOO LARGE AND TAKES +5 MINUTES TO FIT THE MODEL
if (!require(dplyr)) install.packages("dplyr")
if (!require(eflm)) install.packages("eflm")
if (!require(microbenchmark)) install.packages("microbenchmark")
library(dplyr)
library(eflm)
library(microbenchmark)
fout <- "dev/ch1_application1_2.rds"
if (!file.exists(fout)) {
if (!require(yotover)) install.packages("yotover")
library(yotover)
ch1_application1_2 <-  yotov_data("ch1_application1") %>%
filter(year %in% seq(1986, 2006, 4))
ch1_application1_2 <- ch1_application1_2 %>%
mutate(
log_trade = log(trade),
log_dist = log(dist)
)
ch1_application1_2 <- ch1_application1_2 %>%
# Create Yit
group_by(exporter, year) %>%
mutate(
y = sum(trade),
log_y = log(y)
) %>%
# Create Eit
group_by(importer, year) %>%
mutate(
e = sum(trade),
log_e = log(e)
)
ch1_application1_2 <- ch1_application1_2 %>%
# Replicate total_e
group_by(exporter, year) %>%
mutate(total_e = sum(e)) %>%
group_by(year) %>%
mutate(total_e = max(total_e)) %>%
# Replicate rem_exp
group_by(exporter, year) %>%
mutate(
remoteness_exp = sum(dist *  total_e / e),
log_remoteness_exp = log(remoteness_exp)
) %>%
# Replicate total_y
group_by(importer, year) %>%
mutate(total_y = sum(y)) %>%
group_by(year) %>%
mutate(total_y = max(total_y)) %>%
# Replicate rem_imp
group_by(importer, year) %>%
mutate(
remoteness_imp = sum(dist / (y / total_y)),
log_remoteness_imp = log(remoteness_imp)
)
ch1_application1_2 <- ch1_application1_2 %>%
# This merges the columns exporter/importer with year
mutate(
exp_year = paste0(exporter, year),
imp_year = paste0(importer, year)
)
ch1_application1_2 <- ch1_application1_2 %>%
filter(exporter != importer)
saveRDS(ch1_application1_2, fout, compress = "xz")
} else {
ch1_application1_2 <- readRDS("ch1_application1_2.rds")
}
# m1 <- glm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,
#                 family = quasipoisson(link = "log"),
#                 data = ch1_application1_2,
#                 y = FALSE,
#                 model = FALSE
# )
#
# m2 <- eglm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,
#                 family = quasipoisson(link = "log"),
#                 data = ch1_application1_2,
#                 y = FALSE,
#                 model = TRUE
# )
# expect_equal(m1$coefficients, m2$coefficients)
# expect_equal(m1$residuals, m2$residuals)
# expect_equal(m1$fitted.values, m2$fitted.values)
# expect_equal(m1$family$family, m2$family$family)
# expect_equal(m1$family$link, m2$family$link)
# expect_equal(m1$linear.predictors, m2$linear.predictors)
# expect_equal(m1$deviance, m2$deviance)
# expect_equal(m1$aic, m2$aic)
# expect_equal(m1$null.deviance, m2$null.deviance)
# expect_equal(m1$df.residual, m2$df.residual)
# expect_equal(m1$df.null, m2$df.null)
# expect_equal(m1$y, m2$y)
# expect_equal(m1$call$formula, m2$call$formula)
# expect_equal(m1$call$family, m2$call$family)
# expect_equal(m1$call$data, m2$call$data)
# expect_warning(expect_equal(
#   predict(m1, newdata = ch1_application1_2, type = "link"),
#   predict(m2, newdata = ch1_application1_2, type = "link")
# ))
# expect_warning(expect_equal(
#   predict(m1, newdata = ch1_application1_2, type = "response"),
#   predict(m2, newdata = ch1_application1_2, type = "response")
# ))
benchmark_times <- microbenchmark(
glm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,
family = quasipoisson(link = "log"),
data = ch1_application1_2,
y = FALSE,
model = FALSE
),
eglm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,
family = quasipoisson(link = "log"),
data = ch1_application1_2,
y = FALSE,
model = FALSE
),
times = 1L
)
writeLines(benchmark_times, "dev/benchmarktimes.txt")
# Unit: seconds
# expr
# glm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,      family = quasipoisson(link = "log"), data = ch1_application1_2,      y = FALSE, model = FALSE)
# eglm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,      family = quasipoisson(link = "log"), data = ch1_application1_2,      y = FALSE, model = FALSE)
# min        lq      mean    median       uq        max neval
# 78.143386 82.797031 96.416335 85.072021 102.4835 147.671117    10
# 5.842121  5.967758  6.125419  6.039139   6.1037   6.857986    10
benchmark_times
benchmark_times$time
View(benchmark_times)
microbenchmark:::print.microbenchmark(benchmark_times)
writeLines(microbenchmark:::print.microbenchmark(benchmark_times), "dev/benchmarktimes.txt")
aaa = microbenchmark:::print.microbenchmark(benchmark_times)
aaa
View(aaa)
benchmark_times_df <- microbenchmark:::print.microbenchmark(benchmark_times)
class(benchmark_times_df)
if (!require(readr)) install.packages("readr")
library(readr)
Sys.info()
Sys.Date()
Sys.time()
sprintf("dev/benchmarktimes_%s.csv"), Sys.time()
sprintf("dev/benchmarktimes_%s.csv", Sys.time())
droplets
sprintf("dev/benchmarktimes_%s.csv", droplet)
droplet <- "c2-2vcpu-4gb"
sprintf("dev/benchmarktimes_%s.csv", droplet)
write_csv(benchmark_times_df, sprintf("dev/benchmarktimes_%s.csv", droplet))
map(
seq_along(s$slug),
function(x) {
droplets[[x]] <- droplet(droplets[[x]]$id)
}
)
droplets
droplets
View(ch1_application1_2)
ch1_application1_2
ch1_application1_2 %>% select(trade, log_dist, cntg, lang, clny, exp_year, imp_year)
ch1_application1_2 %>% ungroup() %>% select(trade, log_dist, cntg, lang, clny, exp_year, imp_year)
ch1_application1_2 %>% ungroup() %>% select(trade, log_dist, cntg, lang, clny, exp_year, imp_year)
m1
m1 <- glm(trade ~ log_dist + cntg + lang + clny + exp_year + imp_year,
family = quasipoisson(link = "log"),
data = ch1_application1_2,
y = FALSE,
model = FALSE
)
aaa = model.frame(m1)
dim(aaa)
dim(m1$data)
yotover::yotov_clustered_glm(m1$formula, ch1_application1_2)
usethis::edit_r_environ()
usethis::edit_r_profile()
test_file("aaa")
test_file("99-broom-data_error")
library(eflm)
library(eflm)
eglm(mpg ~ log(wt))
eglm(mpg ~ log(wt), data = mtcars)
glm(mpg ~ log(wt), data = mtcars)
export_all()
devtools::load_all()
formula = "mpg ~ log(wt)"
data = mtcars
family = gaussian()
formula = "mpg ~ log(wt)"
data = mtcars
family = gaussian()
intercept = TRUE
weights = NULL
na.action = na.omit
start = NULL
etastart = NULL,
etastart = NULL
mustart = NULL
offset = NULL
maxit = 25
k = 2
formula = "mpg ~ log(wt)"
data = mtcars
family = gaussian()
intercept = TRUE
weights = NULL
na.action = na.omit
start = NULL
etastart = NULL
mustart = NULL
offset = NULL
maxit = 25
k = 2
model = TRUE
singularity.method = c("eigen", "Cholesky", "qr")
x = FALSE
y = TRUE
tol.estimation = 1e-8
tol.solve = .Machine$double.eps
tol.values = 1e-7
tol.vectors = 1e-7
formula = "mpg ~ log(wt)"
data = mtcars
family = gaussian()
intercept = TRUE
weights = NULL
na.action = na.omit
start = NULL
etastart = NULL
mustart = NULL
offset = NULL
maxit = 25
k = 2
model = TRUE
singularity.method = c("eigen", "Cholesky", "qr")
x = FALSE
y = TRUE
tol.estimation = 1e-8
tol.solve = .Machine$double.eps
tol.values = 1e-7
tol.vectors = 1e-7
